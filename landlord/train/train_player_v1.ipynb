{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting landlord-ai\n",
      "  Downloading landlord_ai-0.1.2.tar.gz (8.3 kB)\n",
      "Building wheels for collected packages: landlord-ai\n",
      "  Building wheel for landlord-ai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for landlord-ai: filename=landlord_ai-0.1.2-py3-none-any.whl size=10911 sha256=cac2bd30d51d2c6f92903a40c56e4652db225ac7d47653ed7edf4a3edf9c4d03\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/38/17/72/a99b2187dd9be6cc1ebf0fddc63d16740231db8acf0e3db197\n",
      "Successfully built landlord-ai\n",
      "Installing collected packages: landlord-ai\n",
      "Successfully installed landlord-ai-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install landlord-ai\n",
    "!pip install keras.preprocessing --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "\n",
    "from landlordai.game.player import LearningPlayer_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, path_ids, batch_size=1024, shuffle=True):\n",
    "        \"\"\"Initialization\n",
    "        :param list_IDs: list of all 'label' ids to use in the generator\n",
    "        :param labels: list of image labels (file names)\n",
    "        :param image_path: path to images location\n",
    "        :param mask_path: path to masks location\n",
    "        :param to_fit: True to return X and y, False to return X only\n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param dim: tuple indicating image dimension\n",
    "        :param n_channels: number of image channels\n",
    "        :param n_classes: number of output masks\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        \"\"\"\n",
    "        self.path_ids = path_ids\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.curr_index = 0\n",
    "        self.cache = []\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return 1000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        limit = min(len(self.cache), (self.curr_index + 1) * batch_size)\n",
    "        \n",
    "        X = self.cache[0][self.curr_index * batch_size: limit]\n",
    "        y = self.cache[1][self.curr_index * batch_size: limit]\n",
    "        self.curr_index += 1\n",
    "        \n",
    "        # load a new batch\n",
    "        if limit == len(self.cache):\n",
    "            with open(random.choice(path_ids), 'rb') as f:\n",
    "                self.cache = pickle.load(f)\n",
    "            self.curr_index = 0\n",
    "        \n",
    "        return self.densify(X), y\n",
    "\n",
    "    def densify(self, sparse_matrix):\n",
    "        return np.vstack([x.todense() for x in sparse_matrix])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataGenerator()\n",
    "test = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRU_DIM = 64\n",
    "\n",
    "inp = Input((LearningPlayer_v1.TIMESTEPS, LearningPlayer_v1.TIMESTEP_FEATURES))\n",
    "gru = GRU(64)(inp)\n",
    "history_net = keras.models.Model(inputs=[inp], outputs=gru)\n",
    "history_net.compile(loss=mean_squared_error, optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
