{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting landlord-ai\n",
      "  Downloading landlord_ai-0.1.18.tar.gz (11 kB)\n",
      "Building wheels for collected packages: landlord-ai\n",
      "  Building wheel for landlord-ai (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for landlord-ai: filename=landlord_ai-0.1.18-py3-none-any.whl size=15269 sha256=7cb7e3bc54d4cef08302e22030c41559bd90471345bdfb8beb66a81c311272f8\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/cf/c3/72/f557fc91b3268ac381bbfcb1ef61936da045134fa201ca6e93\n",
      "Successfully built landlord-ai\n",
      "Installing collected packages: landlord-ai\n",
      "Successfully installed landlord-ai-0.1.18\n",
      "Collecting keras.preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 541 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras.preprocessing) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras.preprocessing) (1.18.2)\n",
      "Installing collected packages: keras.preprocessing\n",
      "Successfully installed keras.preprocessing\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.43.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install landlord-ai --upgrade\n",
    "!pip install keras.preprocessing --user\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import Sequence\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from landlordai.game.player import LearningPlayer_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    \"\"\"Generates data for Keras\n",
    "    Sequence based data generator. Suitable for building data generator for training and prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, path_ids, batch_size=1024, shuffle=True, clamp=False, timesteps_length=LearningPlayer_v1.TIMESTEPS):\n",
    "        \"\"\"Initialization\n",
    "        :param list_IDs: list of all 'label' ids to use in the generator\n",
    "        :param labels: list of image labels (file names)\n",
    "        :param image_path: path to images location\n",
    "        :param mask_path: path to masks location\n",
    "        :param to_fit: True to return X and y, False to return X only\n",
    "        :param batch_size: batch size at each iteration\n",
    "        :param dim: tuple indicating image dimension\n",
    "        :param n_channels: number of image channels\n",
    "        :param n_classes: number of output masks\n",
    "        :param shuffle: True to shuffle label indexes after every epoch\n",
    "        \"\"\"\n",
    "        self.path_ids = path_ids\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.clamp = clamp\n",
    "        self.timesteps_length = timesteps_length\n",
    "        \n",
    "        self.load_cache()\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\n",
    "        :return: number of batches per epoch\n",
    "        \"\"\"\n",
    "        return 1000\n",
    "\n",
    "    def load_cache(self):\n",
    "        with open(random.choice(self.path_ids), 'rb') as f:\n",
    "            history_matrices, move_vectors, hand_vectors, y = pickle.load(f)\n",
    "            \n",
    "            if self.shuffle:\n",
    "                p = np.random.permutation(len(history_matrices))\n",
    "                \n",
    "                history_matrices = np.array(history_matrices)[p]\n",
    "                move_vectors = move_vectors[p]\n",
    "                hand_vectors = hand_vectors[p]\n",
    "                y = y[p]\n",
    "        \n",
    "        # unflatten\n",
    "        history_matrices = self.densify(history_matrices)\n",
    "\n",
    "        self.cache = (history_matrices, move_vectors, hand_vectors, y) \n",
    "        self.curr_index = 0\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        limit = min(len(self.cache[0]), (self.curr_index + 1) * self.batch_size)\n",
    "        \n",
    "        #print(self.curr_index * self.batch_size, limit)\n",
    "        history_matrices = self.cache[0][self.curr_index * self.batch_size: limit]\n",
    "        move_vectors = self.cache[1][self.curr_index * self.batch_size: limit]\n",
    "        hand_vectors = self.cache[2][self.curr_index * self.batch_size: limit]\n",
    "        #print(self.curr_index * self.batch_size, limit)\n",
    "        y = self.cache[3][self.curr_index * self.batch_size: limit]\n",
    "        self.curr_index += 1\n",
    "        \n",
    "        # load a new batch\n",
    "        if (self.curr_index + 1) * self.batch_size >= len(self.cache[0]):\n",
    "            self.load_cache()\n",
    "        \n",
    "        return [history_matrices, move_vectors, hand_vectors], self.adjust_y(y)\n",
    "\n",
    "    def densify(self, sparse_matrix):\n",
    "        return np.array([x.todense()[:self.timesteps_length] for x in sparse_matrix])\n",
    "\n",
    "    def adjust_y(self, y):\n",
    "        if not self.clamp:\n",
    "            return y\n",
    "        new_y = []\n",
    "        for elem in y:\n",
    "            if abs(int(elem) - elem) > 1E-4:\n",
    "                new_y.append(0)\n",
    "            else:\n",
    "                new_y.append(elem)\n",
    "        return np.array(new_y)\n",
    "\n",
    "    \n",
    "class PreppedDataGenerator(Sequence):\n",
    "    def __init__(self, path_id, batch_size=1024, timesteps_length=LearningPlayer_v1.TIMESTEPS):\n",
    "        self.path_id = path_id\n",
    "        self.batch_size = batch_size\n",
    "        self.timesteps_length = timesteps_length\n",
    "        \n",
    "        self.load_cache()\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.cache[0]) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        p = np.random.permutation(len(self.cache[0]))\n",
    "        \n",
    "        all_history_matrices = self.cache[0][p]\n",
    "        all_move_vectors = self.cache[1][p]\n",
    "        all_hand_vectors = self.cache[2][p]\n",
    "        all_y = self.cache[3][p]\n",
    "        \n",
    "        self.cache = (all_history_matrices, all_move_vectors, all_hand_vectors, all_y)\n",
    "        \n",
    "    def load_cache(self):\n",
    "        with open(self.path_id, 'rb') as f:\n",
    "            history_matrices, move_vectors, hand_vectors, y = pickle.load(f)\n",
    "            \n",
    "        self.cache = (history_matrices, move_vectors, hand_vectors, np.array(y)) \n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data\n",
    "        :param index: index of the batch\n",
    "        :return: X and y when fitting. X only when predicting\n",
    "        \"\"\"\n",
    "        \n",
    "        history_matrices = self.cache[0][index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        move_vectors = self.cache[1][index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        hand_vectors = self.cache[2][index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        y = self.cache[3][index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        \n",
    "        #return [self.densify(history_matrices), move_vectors, hand_vectors], y\n",
    "        return [history_matrices, move_vectors, hand_vectors], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '4_2_sim5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_folder is not None\n",
    "!rm -r ../data/{data_folder}_agg\n",
    "!gsutil -m cp -r gs://landlord_ai/{data_folder}_agg/ ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = PreppedDataGenerator('../data/' + data_folder + '_agg/train.pkl', batch_size=1 << 14, timesteps_length=50)\n",
    "test_gen = PreppedDataGenerator('../data/' + data_folder + '_agg/test.pkl', batch_size=1 << 14, timesteps_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not np.allclose(train_gen[1][0][0], train_gen[0][0][0])\n",
    "assert len(train_gen[0][0]) == 3\n",
    "for i in range(3):\n",
    "    get_set = train_gen[0][0][0]\n",
    "    if len(get_set.shape) != 3:\n",
    "        print(get_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_bidi():\n",
    "    K.clear_session()\n",
    "    GRU_DIM = 96\n",
    "\n",
    "    history_inp = Input((None, LearningPlayer_v1.TIMESTEP_FEATURES), name='history_inp')\n",
    "    move_inp = Input((LearningPlayer_v1.TIMESTEP_FEATURES, ), name='move_inp')\n",
    "    hand_inp = Input((LearningPlayer_v1.HAND_FEATURES, ), name='hand_inp')\n",
    "    gru = Bidirectional(GRU(GRU_DIM, name='gru'), name='bidi')(history_inp)\n",
    "\n",
    "    concat = Concatenate()([gru, move_inp, hand_inp])\n",
    "    hidden1 = Dense(64, activation='relu', name='hidden1')(concat)\n",
    "    hidden2 = Dense(32, activation='relu', name='hidden2')(BatchNormalization(name='bn1')(hidden1))\n",
    "\n",
    "    output = Dense(1, activation='linear', name='output')(BatchNormalization(name='bn2')(hidden2))\n",
    "    combined_net = keras.models.Model(inputs=[history_inp, move_inp, hand_inp], outputs=output)\n",
    "    combined_net.compile(loss=keras.losses.mean_squared_error, optimizer='adam', metrics=['mean_squared_error'])\n",
    "    return combined_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def has_layer(model, layer):\n",
    "    try:\n",
    "        model.get_layer(layer)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def split_model_triage(composite, model_folder):\n",
    "    best_model = keras.models.load_model(composite)\n",
    "    \n",
    "    split_model(best_model, model_folder)\n",
    "    \n",
    "def split_model(best_model, model_folder):\n",
    "    bn1 = best_model.get_layer('bn1')\n",
    "    bn2 = best_model.get_layer('bn2')\n",
    "    history_net = keras.models.Model(inputs=[best_model.get_layer('history_inp').input], outputs=[best_model.get_layer('bidi').output])\n",
    "\n",
    "    vector_history_inp = Input((best_model.get_layer('bidi').output.shape[1], ), name='vector_history_inp')\n",
    "    \n",
    "    concat = Concatenate()([vector_history_inp, best_model.get_layer('move_inp').output, best_model.get_layer('hand_inp').output])\n",
    "    hidden1 = best_model.get_layer('hidden1')(concat)\n",
    "    hidden2 = best_model.get_layer('hidden2')(bn1(hidden1))\n",
    "    output = best_model.get_layer('output')(bn2(hidden2))\n",
    "\n",
    "    move_inp = best_model.get_layer('move_inp').input\n",
    "    hand_inp = best_model.get_layer('hand_inp').input\n",
    "    position_net = keras.models.Model(inputs=[vector_history_inp, move_inp, hand_inp], outputs=[output])\n",
    "\n",
    "    history_net.save(str(model_folder / 'history.h5'))\n",
    "    position_net.save(str(model_folder / 'position.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check_model(combined_file, net_dir):\n",
    "    sanity_set = train_gen[0]\n",
    "    historical_features, move_vectors, hand_vectors = sanity_set[0]\n",
    "    targets = sanity_set[1]\n",
    "\n",
    "    player = LearningPlayer_v1(name='sanity', net_dir=str(net_dir))\n",
    "    \n",
    "    historical_matrix = player.history_net.predict(historical_features, batch_size=1024)\n",
    "\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    error_1 = metrics.mean_squared_error(targets, player.get_position_predictions(historical_matrix, move_vectors, hand_vectors))\n",
    "    \n",
    "    composite = keras.models.load_model(combined_file)\n",
    "    error_2 = metrics.mean_squared_error(targets, composite.predict([historical_features, move_vectors, hand_vectors], batch_size=1024))\n",
    "    print(combined_file, error_1, error_2)\n",
    "    assert np.abs(error_1 - error_2) < 1E-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def delete_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    for file in path.iterdir():\n",
    "        os.remove(file)\n",
    "    path.rmdir()\n",
    "    \n",
    "def publish_model(i):\n",
    "    combined_file = data_folder + '_combined_' + str(i) + '.h5'\n",
    "    if os.path.exists(combined_file):\n",
    "        model_folder_name = data_folder + '_model' + str(i)\n",
    "\n",
    "        model_folder_path = Path('../models/', model_folder_name)\n",
    "        delete_dir(model_folder_path)\n",
    "        model_folder_path.mkdir()\n",
    "\n",
    "        split_model_triage(combined_file, model_folder_path)\n",
    "        sanity_check_model(combined_file, model_folder_path)\n",
    "        print(model_folder_name)\n",
    "        subprocess.check_output(['gsutil', 'cp', '-r', '../models/' + model_folder_name + '/*', 'gs://landlord_ai/models/' + model_folder_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
<<<<<<< Updated upstream
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.7768 - mean_squared_error: 0.7768 - val_loss: 0.6630 - val_mean_squared_error: 0.6585\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.65847, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.3795 - mean_squared_error: 0.3795 - val_loss: 0.4031 - val_mean_squared_error: 0.3940\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.65847 to 0.39395, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.3400 - mean_squared_error: 0.3400 - val_loss: 0.3391 - val_mean_squared_error: 0.3374\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.39395 to 0.33736, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.3205 - mean_squared_error: 0.3205 - val_loss: 0.2988 - val_mean_squared_error: 0.3148\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.33736 to 0.31476, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 288s 288ms/step - loss: 0.3073 - mean_squared_error: 0.3073 - val_loss: 0.2985 - val_mean_squared_error: 0.3111\n",
      "\n",
      "Epoch 00005: val_mean_squared_error improved from 0.31476 to 0.31108, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.2883 - mean_squared_error: 0.2883 - val_loss: 0.3087 - val_mean_squared_error: 0.2970\n",
      "\n",
      "Epoch 00007: val_mean_squared_error improved from 0.31037 to 0.29697, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.2802 - mean_squared_error: 0.2802 - val_loss: 0.3214 - val_mean_squared_error: 0.3144\n",
      "\n",
      "Epoch 00008: val_mean_squared_error did not improve from 0.29697\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.2736 - mean_squared_error: 0.2736 - val_loss: 0.2863 - val_mean_squared_error: 0.2990\n",
      "\n",
      "Epoch 00009: val_mean_squared_error did not improve from 0.29697\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.2672 - mean_squared_error: 0.2672 - val_loss: 0.2733 - val_mean_squared_error: 0.2743\n",
      "\n",
      "Epoch 00010: val_mean_squared_error improved from 0.29697 to 0.27428, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.2612 - mean_squared_error: 0.2612 - val_loss: 0.2713 - val_mean_squared_error: 0.2718\n",
      "\n",
      "Epoch 00011: val_mean_squared_error improved from 0.27428 to 0.27177, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.2543 - mean_squared_error: 0.2543 - val_loss: 0.3009 - val_mean_squared_error: 0.2883\n",
      "\n",
      "Epoch 00012: val_mean_squared_error did not improve from 0.27177\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 280s 280ms/step - loss: 0.2481 - mean_squared_error: 0.2481 - val_loss: 0.2671 - val_mean_squared_error: 0.2628\n",
      "\n",
      "Epoch 00013: val_mean_squared_error improved from 0.27177 to 0.26276, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 283s 283ms/step - loss: 0.2420 - mean_squared_error: 0.2420 - val_loss: 0.2450 - val_mean_squared_error: 0.2532\n",
      "\n",
      "Epoch 00014: val_mean_squared_error improved from 0.26276 to 0.25321, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 288s 288ms/step - loss: 0.2361 - mean_squared_error: 0.2361 - val_loss: 0.2542 - val_mean_squared_error: 0.2559\n",
      "\n",
      "Epoch 00015: val_mean_squared_error did not improve from 0.25321\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.2311 - mean_squared_error: 0.2311 - val_loss: 0.2441 - val_mean_squared_error: 0.2445\n",
      "\n",
      "Epoch 00016: val_mean_squared_error improved from 0.25321 to 0.24447, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 289s 289ms/step - loss: 0.2263 - mean_squared_error: 0.2263 - val_loss: 0.2399 - val_mean_squared_error: 0.2371\n",
      "\n",
      "Epoch 00017: val_mean_squared_error improved from 0.24447 to 0.23714, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.2220 - mean_squared_error: 0.2220 - val_loss: 0.2405 - val_mean_squared_error: 0.2361\n",
      "\n",
      "Epoch 00018: val_mean_squared_error improved from 0.23714 to 0.23609, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 288s 288ms/step - loss: 0.2181 - mean_squared_error: 0.2181 - val_loss: 0.2274 - val_mean_squared_error: 0.2286\n",
      "\n",
      "Epoch 00019: val_mean_squared_error improved from 0.23609 to 0.22856, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.2143 - mean_squared_error: 0.2143 - val_loss: 0.2270 - val_mean_squared_error: 0.2290\n",
      "\n",
      "Epoch 00020: val_mean_squared_error did not improve from 0.22856\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.2112 - mean_squared_error: 0.2112 - val_loss: 0.2191 - val_mean_squared_error: 0.2232\n",
      "\n",
      "Epoch 00021: val_mean_squared_error improved from 0.22856 to 0.22316, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 289s 289ms/step - loss: 0.2079 - mean_squared_error: 0.2079 - val_loss: 0.2177 - val_mean_squared_error: 0.2224\n",
      "\n",
      "Epoch 00022: val_mean_squared_error improved from 0.22316 to 0.22236, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.2055 - mean_squared_error: 0.2055 - val_loss: 0.2221 - val_mean_squared_error: 0.2197\n",
      "\n",
      "Epoch 00023: val_mean_squared_error improved from 0.22236 to 0.21971, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 289s 289ms/step - loss: 0.2026 - mean_squared_error: 0.2026 - val_loss: 0.2216 - val_mean_squared_error: 0.2252\n",
      "\n",
      "Epoch 00024: val_mean_squared_error did not improve from 0.21971\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.2006 - mean_squared_error: 0.2006 - val_loss: 0.2166 - val_mean_squared_error: 0.2185\n",
      "\n",
      "Epoch 00025: val_mean_squared_error improved from 0.21971 to 0.21852, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 289s 289ms/step - loss: 0.1982 - mean_squared_error: 0.1982 - val_loss: 0.2131 - val_mean_squared_error: 0.2149\n",
      "\n",
      "Epoch 00026: val_mean_squared_error improved from 0.21852 to 0.21487, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.1959 - mean_squared_error: 0.1959 - val_loss: 0.2122 - val_mean_squared_error: 0.2118\n",
      "\n",
      "Epoch 00027: val_mean_squared_error improved from 0.21487 to 0.21182, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.1945 - mean_squared_error: 0.1945 - val_loss: 0.2051 - val_mean_squared_error: 0.2110\n",
      "\n",
      "Epoch 00028: val_mean_squared_error improved from 0.21182 to 0.21105, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 290s 290ms/step - loss: 0.1923 - mean_squared_error: 0.1923 - val_loss: 0.2083 - val_mean_squared_error: 0.2089\n",
      "\n",
      "Epoch 00029: val_mean_squared_error improved from 0.21105 to 0.20891, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.1906 - mean_squared_error: 0.1906 - val_loss: 0.2082 - val_mean_squared_error: 0.2071\n",
      "\n",
      "Epoch 00030: val_mean_squared_error improved from 0.20891 to 0.20710, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.1890 - mean_squared_error: 0.1890 - val_loss: 0.2074 - val_mean_squared_error: 0.2039\n",
      "\n",
      "Epoch 00031: val_mean_squared_error improved from 0.20710 to 0.20387, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 282s 282ms/step - loss: 0.1873 - mean_squared_error: 0.1873 - val_loss: 0.2040 - val_mean_squared_error: 0.2023\n",
      "\n",
      "Epoch 00032: val_mean_squared_error improved from 0.20387 to 0.20232, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.1860 - mean_squared_error: 0.1860 - val_loss: 0.2025 - val_mean_squared_error: 0.2053\n",
      "\n",
      "Epoch 00033: val_mean_squared_error did not improve from 0.20232\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.1844 - mean_squared_error: 0.1844 - val_loss: 0.2076 - val_mean_squared_error: 0.2030\n",
      "\n",
      "Epoch 00034: val_mean_squared_error did not improve from 0.20232\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1833 - mean_squared_error: 0.1833 - val_loss: 0.1959 - val_mean_squared_error: 0.1997\n",
      "\n",
      "Epoch 00035: val_mean_squared_error improved from 0.20232 to 0.19971, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.1819 - mean_squared_error: 0.1819 - val_loss: 0.2043 - val_mean_squared_error: 0.2005\n",
      "\n",
      "Epoch 00036: val_mean_squared_error did not improve from 0.19971\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 285s 285ms/step - loss: 0.1810 - mean_squared_error: 0.1810 - val_loss: 0.2034 - val_mean_squared_error: 0.2026\n",
      "\n",
      "Epoch 00037: val_mean_squared_error did not improve from 0.19971\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 288s 288ms/step - loss: 0.1797 - mean_squared_error: 0.1797 - val_loss: 0.1991 - val_mean_squared_error: 0.1990\n",
      "\n",
      "Epoch 00038: val_mean_squared_error improved from 0.19971 to 0.19900, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1787 - mean_squared_error: 0.1787 - val_loss: 0.2099 - val_mean_squared_error: 0.2033\n",
      "\n",
      "Epoch 00039: val_mean_squared_error did not improve from 0.19900\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1778 - mean_squared_error: 0.1778 - val_loss: 0.1968 - val_mean_squared_error: 0.2006\n",
      "\n",
      "Epoch 00040: val_mean_squared_error did not improve from 0.19900\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.1765 - mean_squared_error: 0.1765 - val_loss: 0.1922 - val_mean_squared_error: 0.1971\n",
      "\n",
      "Epoch 00041: val_mean_squared_error improved from 0.19900 to 0.19707, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1759 - mean_squared_error: 0.1759 - val_loss: 0.1989 - val_mean_squared_error: 0.1973\n",
      "\n",
      "Epoch 00042: val_mean_squared_error did not improve from 0.19707\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.1749 - mean_squared_error: 0.1749 - val_loss: 0.1971 - val_mean_squared_error: 0.1932\n",
      "\n",
      "Epoch 00043: val_mean_squared_error improved from 0.19707 to 0.19324, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1741 - mean_squared_error: 0.1741 - val_loss: 0.2040 - val_mean_squared_error: 0.1954\n",
      "\n",
      "Epoch 00044: val_mean_squared_error did not improve from 0.19324\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.1734 - mean_squared_error: 0.1734 - val_loss: 0.1949 - val_mean_squared_error: 0.1944\n",
      "\n",
      "Epoch 00045: val_mean_squared_error did not improve from 0.19324\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1726 - mean_squared_error: 0.1726 - val_loss: 0.1944 - val_mean_squared_error: 0.1920\n",
      "\n",
      "Epoch 00046: val_mean_squared_error improved from 0.19324 to 0.19201, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1722 - mean_squared_error: 0.1722 - val_loss: 0.1953 - val_mean_squared_error: 0.1909\n",
      "\n",
      "Epoch 00047: val_mean_squared_error improved from 0.19201 to 0.19090, saving model to 4_2_sim4_combined_0.h5\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.1713 - mean_squared_error: 0.1713 - val_loss: 0.1870 - val_mean_squared_error: 0.1917\n",
      "\n",
      "Epoch 00048: val_mean_squared_error did not improve from 0.19090\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.1707 - mean_squared_error: 0.1707 - val_loss: 0.1908 - val_mean_squared_error: 0.1930\n",
      "\n",
      "Epoch 00049: val_mean_squared_error did not improve from 0.19090\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 287s 287ms/step - loss: 0.1701 - mean_squared_error: 0.1701 - val_loss: 0.1857 - val_mean_squared_error: 0.1907\n",
      "\n",
      "Epoch 00050: val_mean_squared_error improved from 0.19090 to 0.19069, saving model to 4_2_sim4_combined_0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2_sim4_combined_0.h5 0.17558248987090347 0.17558248987090347\n",
      "4_2_sim4_model0\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.7155 - mean_squared_error: 0.7155 - val_loss: 0.4575 - val_mean_squared_error: 0.4501\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.45009, saving model to 4_2_sim4_combined_1.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 283s 283ms/step - loss: 0.3714 - mean_squared_error: 0.3714 - val_loss: 0.3693 - val_mean_squared_error: 0.3587\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.45009 to 0.35870, saving model to 4_2_sim4_combined_1.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.3358 - mean_squared_error: 0.3358 - val_loss: 0.3764 - val_mean_squared_error: 0.3896\n",
      "\n",
      "Epoch 00003: val_mean_squared_error did not improve from 0.35870\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 283s 283ms/step - loss: 0.3186 - mean_squared_error: 0.3186 - val_loss: 0.3741 - val_mean_squared_error: 0.3715\n",
      "\n",
      "Epoch 00004: val_mean_squared_error did not improve from 0.35870\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.3067 - mean_squared_error: 0.3067 - val_loss: 0.3812 - val_mean_squared_error: 0.3811\n",
      "\n",
      "Epoch 00005: val_mean_squared_error did not improve from 0.35870\n",
      "Epoch 00005: early stopping\n"
=======
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.7859 - mean_squared_error: 0.7859 - val_loss: 0.4972 - val_mean_squared_error: 0.4900\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.49001, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.3629 - mean_squared_error: 0.3629 - val_loss: 0.3523 - val_mean_squared_error: 0.3634\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.49001 to 0.36343, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 325s 325ms/step - loss: 0.3131 - mean_squared_error: 0.3131 - val_loss: 0.3157 - val_mean_squared_error: 0.3266\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.36343 to 0.32655, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2940 - mean_squared_error: 0.2940 - val_loss: 0.3018 - val_mean_squared_error: 0.3076\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.32655 to 0.30756, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2821 - mean_squared_error: 0.2821 - val_loss: 0.3615 - val_mean_squared_error: 0.3677\n",
      "\n",
      "Epoch 00005: val_mean_squared_error did not improve from 0.30756\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 326s 326ms/step - loss: 0.2733 - mean_squared_error: 0.2733 - val_loss: 0.3417 - val_mean_squared_error: 0.3384\n",
      "\n",
      "Epoch 00006: val_mean_squared_error did not improve from 0.30756\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2648 - mean_squared_error: 0.2648 - val_loss: 0.2702 - val_mean_squared_error: 0.2779\n",
      "\n",
      "Epoch 00007: val_mean_squared_error improved from 0.30756 to 0.27789, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2586 - mean_squared_error: 0.2586 - val_loss: 0.2802 - val_mean_squared_error: 0.2814\n",
      "\n",
      "Epoch 00008: val_mean_squared_error did not improve from 0.27789\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2534 - mean_squared_error: 0.2534 - val_loss: 0.2672 - val_mean_squared_error: 0.2656\n",
      "\n",
      "Epoch 00009: val_mean_squared_error improved from 0.27789 to 0.26555, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2491 - mean_squared_error: 0.2491 - val_loss: 0.2543 - val_mean_squared_error: 0.2711\n",
      "\n",
      "Epoch 00010: val_mean_squared_error did not improve from 0.26555\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 326s 326ms/step - loss: 0.2449 - mean_squared_error: 0.2449 - val_loss: 0.2607 - val_mean_squared_error: 0.2627\n",
      "\n",
      "Epoch 00011: val_mean_squared_error improved from 0.26555 to 0.26267, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2410 - mean_squared_error: 0.2410 - val_loss: 0.2685 - val_mean_squared_error: 0.2752\n",
      "\n",
      "Epoch 00012: val_mean_squared_error did not improve from 0.26267\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2379 - mean_squared_error: 0.2379 - val_loss: 0.2726 - val_mean_squared_error: 0.2632\n",
      "\n",
      "Epoch 00013: val_mean_squared_error did not improve from 0.26267\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.2345 - mean_squared_error: 0.2345 - val_loss: 0.2472 - val_mean_squared_error: 0.2495\n",
      "\n",
      "Epoch 00014: val_mean_squared_error improved from 0.26267 to 0.24955, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.2309 - mean_squared_error: 0.2309 - val_loss: 0.2553 - val_mean_squared_error: 0.2470\n",
      "\n",
      "Epoch 00015: val_mean_squared_error improved from 0.24955 to 0.24704, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2279 - mean_squared_error: 0.2279 - val_loss: 0.2439 - val_mean_squared_error: 0.2446\n",
      "\n",
      "Epoch 00016: val_mean_squared_error improved from 0.24704 to 0.24464, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 326s 326ms/step - loss: 0.2250 - mean_squared_error: 0.2250 - val_loss: 0.2311 - val_mean_squared_error: 0.2371\n",
      "\n",
      "Epoch 00017: val_mean_squared_error improved from 0.24464 to 0.23706, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2219 - mean_squared_error: 0.2219 - val_loss: 0.2573 - val_mean_squared_error: 0.2380\n",
      "\n",
      "Epoch 00018: val_mean_squared_error did not improve from 0.23706\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.2192 - mean_squared_error: 0.2192 - val_loss: 0.2560 - val_mean_squared_error: 0.2431\n",
      "\n",
      "Epoch 00019: val_mean_squared_error did not improve from 0.23706\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2162 - mean_squared_error: 0.2162 - val_loss: 0.2281 - val_mean_squared_error: 0.2345\n",
      "\n",
      "Epoch 00020: val_mean_squared_error improved from 0.23706 to 0.23453, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2138 - mean_squared_error: 0.2138 - val_loss: 0.2481 - val_mean_squared_error: 0.2415\n",
      "\n",
      "Epoch 00021: val_mean_squared_error did not improve from 0.23453\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 325s 325ms/step - loss: 0.2115 - mean_squared_error: 0.2115 - val_loss: 0.2239 - val_mean_squared_error: 0.2318\n",
      "\n",
      "Epoch 00022: val_mean_squared_error improved from 0.23453 to 0.23181, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.2090 - mean_squared_error: 0.2090 - val_loss: 0.2289 - val_mean_squared_error: 0.2277\n",
      "\n",
      "Epoch 00023: val_mean_squared_error improved from 0.23181 to 0.22769, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2071 - mean_squared_error: 0.2071 - val_loss: 0.2257 - val_mean_squared_error: 0.2201\n",
      "\n",
      "Epoch 00024: val_mean_squared_error improved from 0.22769 to 0.22007, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 325s 325ms/step - loss: 0.2050 - mean_squared_error: 0.2050 - val_loss: 0.2378 - val_mean_squared_error: 0.2376\n",
      "\n",
      "Epoch 00025: val_mean_squared_error did not improve from 0.22007\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2031 - mean_squared_error: 0.2031 - val_loss: 0.2183 - val_mean_squared_error: 0.2227\n",
      "\n",
      "Epoch 00026: val_mean_squared_error did not improve from 0.22007\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 325s 325ms/step - loss: 0.2012 - mean_squared_error: 0.2012 - val_loss: 0.2125 - val_mean_squared_error: 0.2145\n",
      "\n",
      "Epoch 00027: val_mean_squared_error improved from 0.22007 to 0.21445, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 325s 325ms/step - loss: 0.1993 - mean_squared_error: 0.1993 - val_loss: 0.2258 - val_mean_squared_error: 0.2180\n",
      "\n",
      "Epoch 00028: val_mean_squared_error did not improve from 0.21445\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.1981 - mean_squared_error: 0.1981 - val_loss: 0.2172 - val_mean_squared_error: 0.2131\n",
      "\n",
      "Epoch 00029: val_mean_squared_error improved from 0.21445 to 0.21309, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.1964 - mean_squared_error: 0.1964 - val_loss: 0.2145 - val_mean_squared_error: 0.2136\n",
      "\n",
      "Epoch 00030: val_mean_squared_error did not improve from 0.21309\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.1949 - mean_squared_error: 0.1949 - val_loss: 0.2164 - val_mean_squared_error: 0.2140\n",
      "\n",
      "Epoch 00031: val_mean_squared_error did not improve from 0.21309\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.1937 - mean_squared_error: 0.1937 - val_loss: 0.2121 - val_mean_squared_error: 0.2090\n",
      "\n",
      "Epoch 00032: val_mean_squared_error improved from 0.21309 to 0.20899, saving model to 4_2_sim4_combined_10.h5\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.1924 - mean_squared_error: 0.1924 - val_loss: 0.2005 - val_mean_squared_error: 0.2095\n",
      "\n",
      "Epoch 00033: val_mean_squared_error did not improve from 0.20899\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.1913 - mean_squared_error: 0.1913 - val_loss: 0.2151 - val_mean_squared_error: 0.2119\n",
      "\n",
      "Epoch 00034: val_mean_squared_error did not improve from 0.20899\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 335s 335ms/step - loss: 0.1901 - mean_squared_error: 0.1901 - val_loss: 0.2110 - val_mean_squared_error: 0.2116\n",
      "\n",
      "Epoch 00035: val_mean_squared_error did not improve from 0.20899\n",
      "Epoch 00035: early stopping\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "4_2_sim4_combined_1.h5 0.35193981065820845 0.35193981065820845\n",
      "4_2_sim4_model1\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 282s 282ms/step - loss: 0.7697 - mean_squared_error: 0.7697 - val_loss: 0.6785 - val_mean_squared_error: 0.6833\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.68331, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.3882 - mean_squared_error: 0.3882 - val_loss: 0.4289 - val_mean_squared_error: 0.4190\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.68331 to 0.41899, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.3722 - val_mean_squared_error: 0.3730\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.41899 to 0.37301, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.3233 - mean_squared_error: 0.3233 - val_loss: 0.4116 - val_mean_squared_error: 0.4119\n",
      "\n",
      "Epoch 00004: val_mean_squared_error did not improve from 0.37301\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.3104 - mean_squared_error: 0.3104 - val_loss: 0.3097 - val_mean_squared_error: 0.3133\n",
      "\n",
      "Epoch 00005: val_mean_squared_error improved from 0.37301 to 0.31333, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 280s 280ms/step - loss: 0.2999 - mean_squared_error: 0.2999 - val_loss: 0.3227 - val_mean_squared_error: 0.3187\n",
      "\n",
      "Epoch 00006: val_mean_squared_error did not improve from 0.31333\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 282s 282ms/step - loss: 0.2917 - mean_squared_error: 0.2917 - val_loss: 0.3153 - val_mean_squared_error: 0.3099\n",
      "\n",
      "Epoch 00007: val_mean_squared_error improved from 0.31333 to 0.30992, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 286s 286ms/step - loss: 0.2845 - mean_squared_error: 0.2845 - val_loss: 0.2855 - val_mean_squared_error: 0.2983\n",
      "\n",
      "Epoch 00008: val_mean_squared_error improved from 0.30992 to 0.29831, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 282s 282ms/step - loss: 0.2785 - mean_squared_error: 0.2785 - val_loss: 0.2922 - val_mean_squared_error: 0.2899\n",
      "\n",
      "Epoch 00009: val_mean_squared_error improved from 0.29831 to 0.28987, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.2719 - mean_squared_error: 0.2719 - val_loss: 0.3034 - val_mean_squared_error: 0.3023\n",
      "\n",
      "Epoch 00010: val_mean_squared_error did not improve from 0.28987\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 281s 281ms/step - loss: 0.2665 - mean_squared_error: 0.2665 - val_loss: 0.2954 - val_mean_squared_error: 0.2879\n",
      "\n",
      "Epoch 00011: val_mean_squared_error improved from 0.28987 to 0.28786, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.2609 - mean_squared_error: 0.2609 - val_loss: 0.2994 - val_mean_squared_error: 0.3012\n",
      "\n",
      "Epoch 00012: val_mean_squared_error did not improve from 0.28786\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 283s 283ms/step - loss: 0.2558 - mean_squared_error: 0.2558 - val_loss: 0.2951 - val_mean_squared_error: 0.2961\n",
      "\n",
      "Epoch 00013: val_mean_squared_error did not improve from 0.28786\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 284s 284ms/step - loss: 0.2511 - mean_squared_error: 0.2511 - val_loss: 0.2489 - val_mean_squared_error: 0.2610\n",
      "\n",
      "Epoch 00014: val_mean_squared_error improved from 0.28786 to 0.26100, saving model to 4_2_sim4_combined_2.h5\n",
      "Epoch 15/50\n",
      " 135/1000 [===>..........................] - ETA: 4:13 - loss: 0.2467 - mean_squared_error: 0.2467"
=======
      "4_2_sim4_combined_10.h5 0.18820317820023036 0.18820317820023036\n",
      "4_2_sim4_model10\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.8693 - mean_squared_error: 0.8693 - val_loss: 0.5044 - val_mean_squared_error: 0.4821\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.48205, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.3683 - mean_squared_error: 0.3683 - val_loss: 0.3429 - val_mean_squared_error: 0.3486\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.48205 to 0.34859, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.3184 - mean_squared_error: 0.3184 - val_loss: 0.3572 - val_mean_squared_error: 0.3551\n",
      "\n",
      "Epoch 00003: val_mean_squared_error did not improve from 0.34859\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.2981 - mean_squared_error: 0.2981 - val_loss: 0.3035 - val_mean_squared_error: 0.3261\n",
      "\n",
      "Epoch 00004: val_mean_squared_error improved from 0.34859 to 0.32607, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.2856 - mean_squared_error: 0.2856 - val_loss: 0.3268 - val_mean_squared_error: 0.3255\n",
      "\n",
      "Epoch 00005: val_mean_squared_error improved from 0.32607 to 0.32546, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.2757 - mean_squared_error: 0.2757 - val_loss: 0.2972 - val_mean_squared_error: 0.3035\n",
      "\n",
      "Epoch 00006: val_mean_squared_error improved from 0.32546 to 0.30346, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 333s 333ms/step - loss: 0.2684 - mean_squared_error: 0.2684 - val_loss: 0.3903 - val_mean_squared_error: 0.3981\n",
      "\n",
      "Epoch 00007: val_mean_squared_error did not improve from 0.30346\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 334s 334ms/step - loss: 0.2619 - mean_squared_error: 0.2619 - val_loss: 0.2975 - val_mean_squared_error: 0.3106\n",
      "\n",
      "Epoch 00008: val_mean_squared_error did not improve from 0.30346\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2564 - mean_squared_error: 0.2564 - val_loss: 0.2713 - val_mean_squared_error: 0.2762\n",
      "\n",
      "Epoch 00009: val_mean_squared_error improved from 0.30346 to 0.27622, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 333s 333ms/step - loss: 0.2514 - mean_squared_error: 0.2514 - val_loss: 0.2811 - val_mean_squared_error: 0.2652\n",
      "\n",
      "Epoch 00010: val_mean_squared_error improved from 0.27622 to 0.26515, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.2469 - mean_squared_error: 0.2469 - val_loss: 0.2715 - val_mean_squared_error: 0.2812\n",
      "\n",
      "Epoch 00011: val_mean_squared_error did not improve from 0.26515\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 334s 334ms/step - loss: 0.2430 - mean_squared_error: 0.2430 - val_loss: 0.2535 - val_mean_squared_error: 0.2565\n",
      "\n",
      "Epoch 00012: val_mean_squared_error improved from 0.26515 to 0.25655, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 334s 334ms/step - loss: 0.2396 - mean_squared_error: 0.2396 - val_loss: 0.2498 - val_mean_squared_error: 0.2517\n",
      "\n",
      "Epoch 00013: val_mean_squared_error improved from 0.25655 to 0.25166, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2361 - mean_squared_error: 0.2361 - val_loss: 0.2626 - val_mean_squared_error: 0.2617\n",
      "\n",
      "Epoch 00014: val_mean_squared_error did not improve from 0.25166\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.2329 - mean_squared_error: 0.2329 - val_loss: 0.2694 - val_mean_squared_error: 0.2713\n",
      "\n",
      "Epoch 00015: val_mean_squared_error did not improve from 0.25166\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.2300 - mean_squared_error: 0.2300 - val_loss: 0.2331 - val_mean_squared_error: 0.2389\n",
      "\n",
      "Epoch 00016: val_mean_squared_error improved from 0.25166 to 0.23892, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2264 - mean_squared_error: 0.2264 - val_loss: 0.2504 - val_mean_squared_error: 0.2504\n",
      "\n",
      "Epoch 00017: val_mean_squared_error did not improve from 0.23892\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.2235 - mean_squared_error: 0.2235 - val_loss: 0.2426 - val_mean_squared_error: 0.2357\n",
      "\n",
      "Epoch 00018: val_mean_squared_error improved from 0.23892 to 0.23571, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.2206 - mean_squared_error: 0.2206 - val_loss: 0.2462 - val_mean_squared_error: 0.2411\n",
      "\n",
      "Epoch 00019: val_mean_squared_error did not improve from 0.23571\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.2178 - mean_squared_error: 0.2178 - val_loss: 0.2333 - val_mean_squared_error: 0.2308\n",
      "\n",
      "Epoch 00020: val_mean_squared_error improved from 0.23571 to 0.23075, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.2152 - mean_squared_error: 0.2152 - val_loss: 0.2165 - val_mean_squared_error: 0.2270\n",
      "\n",
      "Epoch 00021: val_mean_squared_error improved from 0.23075 to 0.22700, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2127 - mean_squared_error: 0.2127 - val_loss: 0.2110 - val_mean_squared_error: 0.2264\n",
      "\n",
      "Epoch 00022: val_mean_squared_error improved from 0.22700 to 0.22636, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.2102 - mean_squared_error: 0.2102 - val_loss: 0.2155 - val_mean_squared_error: 0.2218\n",
      "\n",
      "Epoch 00023: val_mean_squared_error improved from 0.22636 to 0.22176, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.2083 - mean_squared_error: 0.2083 - val_loss: 0.2195 - val_mean_squared_error: 0.2203\n",
      "\n",
      "Epoch 00024: val_mean_squared_error improved from 0.22176 to 0.22027, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.2061 - mean_squared_error: 0.2061 - val_loss: 0.2259 - val_mean_squared_error: 0.2269\n",
      "\n",
      "Epoch 00025: val_mean_squared_error did not improve from 0.22027\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.2041 - mean_squared_error: 0.2041 - val_loss: 0.2138 - val_mean_squared_error: 0.2163\n",
      "\n",
      "Epoch 00026: val_mean_squared_error improved from 0.22027 to 0.21634, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2025 - mean_squared_error: 0.2025 - val_loss: 0.2204 - val_mean_squared_error: 0.2145\n",
      "\n",
      "Epoch 00027: val_mean_squared_error improved from 0.21634 to 0.21450, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.2008 - mean_squared_error: 0.2008 - val_loss: 0.2252 - val_mean_squared_error: 0.2261\n",
      "\n",
      "Epoch 00028: val_mean_squared_error did not improve from 0.21450\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 331s 331ms/step - loss: 0.1992 - mean_squared_error: 0.1992 - val_loss: 0.2134 - val_mean_squared_error: 0.2145\n",
      "\n",
      "Epoch 00029: val_mean_squared_error improved from 0.21450 to 0.21446, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.1980 - mean_squared_error: 0.1980 - val_loss: 0.2300 - val_mean_squared_error: 0.2276\n",
      "\n",
      "Epoch 00030: val_mean_squared_error did not improve from 0.21446\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.1963 - mean_squared_error: 0.1963 - val_loss: 0.2146 - val_mean_squared_error: 0.2244\n",
      "\n",
      "Epoch 00031: val_mean_squared_error did not improve from 0.21446\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 333s 333ms/step - loss: 0.1951 - mean_squared_error: 0.1951 - val_loss: 0.2150 - val_mean_squared_error: 0.2123\n",
      "\n",
      "Epoch 00032: val_mean_squared_error improved from 0.21446 to 0.21235, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.1941 - mean_squared_error: 0.1941 - val_loss: 0.2174 - val_mean_squared_error: 0.2118\n",
      "\n",
      "Epoch 00033: val_mean_squared_error improved from 0.21235 to 0.21175, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.1926 - mean_squared_error: 0.1926 - val_loss: 0.2110 - val_mean_squared_error: 0.2130\n",
      "\n",
      "Epoch 00034: val_mean_squared_error did not improve from 0.21175\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.1918 - mean_squared_error: 0.1918 - val_loss: 0.2087 - val_mean_squared_error: 0.2095\n",
      "\n",
      "Epoch 00035: val_mean_squared_error improved from 0.21175 to 0.20953, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 327s 327ms/step - loss: 0.1906 - mean_squared_error: 0.1906 - val_loss: 0.2095 - val_mean_squared_error: 0.2046\n",
      "\n",
      "Epoch 00036: val_mean_squared_error improved from 0.20953 to 0.20457, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.1896 - mean_squared_error: 0.1896 - val_loss: 0.2142 - val_mean_squared_error: 0.2069\n",
      "\n",
      "Epoch 00037: val_mean_squared_error did not improve from 0.20457\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 326s 326ms/step - loss: 0.1887 - mean_squared_error: 0.1887 - val_loss: 0.2084 - val_mean_squared_error: 0.2091\n",
      "\n",
      "Epoch 00038: val_mean_squared_error did not improve from 0.20457\n",
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.1876 - mean_squared_error: 0.1876 - val_loss: 0.2077 - val_mean_squared_error: 0.2035\n",
      "\n",
      "Epoch 00039: val_mean_squared_error improved from 0.20457 to 0.20355, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 328s 328ms/step - loss: 0.1869 - mean_squared_error: 0.1869 - val_loss: 0.2106 - val_mean_squared_error: 0.2050\n",
      "\n",
      "Epoch 00040: val_mean_squared_error did not improve from 0.20355\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 325s 325ms/step - loss: 0.1858 - mean_squared_error: 0.1858 - val_loss: 0.2064 - val_mean_squared_error: 0.2009\n",
      "\n",
      "Epoch 00041: val_mean_squared_error improved from 0.20355 to 0.20093, saving model to 4_2_sim4_combined_11.h5\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.1852 - mean_squared_error: 0.1852 - val_loss: 0.2085 - val_mean_squared_error: 0.2047\n",
      "\n",
      "Epoch 00042: val_mean_squared_error did not improve from 0.20093\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.1844 - mean_squared_error: 0.1844 - val_loss: 0.2015 - val_mean_squared_error: 0.2031\n",
      "\n",
      "Epoch 00043: val_mean_squared_error did not improve from 0.20093\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 329s 329ms/step - loss: 0.1836 - mean_squared_error: 0.1836 - val_loss: 0.2039 - val_mean_squared_error: 0.2015\n",
      "\n",
      "Epoch 00044: val_mean_squared_error did not improve from 0.20093\n",
      "Epoch 00044: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2_sim4_combined_11.h5 0.19086065280889786 0.19086065280889786\n",
      "4_2_sim4_model11\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 333s 333ms/step - loss: 0.7474 - mean_squared_error: 0.7474 - val_loss: 0.5493 - val_mean_squared_error: 0.5528\n",
      "\n",
      "Epoch 00001: val_mean_squared_error improved from inf to 0.55285, saving model to 4_2_sim4_combined_12.h5\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 332s 332ms/step - loss: 0.3650 - mean_squared_error: 0.3650 - val_loss: 0.4160 - val_mean_squared_error: 0.4074\n",
      "\n",
      "Epoch 00002: val_mean_squared_error improved from 0.55285 to 0.40735, saving model to 4_2_sim4_combined_12.h5\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 330s 330ms/step - loss: 0.3288 - mean_squared_error: 0.3288 - val_loss: 0.3654 - val_mean_squared_error: 0.3668\n",
      "\n",
      "Epoch 00003: val_mean_squared_error improved from 0.40735 to 0.36678, saving model to 4_2_sim4_combined_12.h5\n",
      "Epoch 4/50\n",
      " 506/1000 [==============>...............] - ETA: 2:41 - loss: 0.3134 - mean_squared_error: 0.3134"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-39d1a64a5b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_combined_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mpublish_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-39d1a64a5b26>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m               )\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3719\u001b[0m               'You must feed a value for placeholder %s' % (tensor,))\n\u001b[1;32m   3720\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3721\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3722\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m         \u001b[0;31m# Temporary workaround due to `convert_to_tensor` not casting floats.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "def train_model(fname='model.h5'):\n",
    "    combined_net = create_model_bidi()\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_mean_squared_error', mode='min', verbose=1, patience=3),\n",
    "        ModelCheckpoint(fname, monitor='val_mean_squared_error', mode='min', verbose=1, save_best_only=True)\n",
    "    ]\n",
    "\n",
    "    combined_net.fit_generator(train_gen,\n",
    "                                steps_per_epoch=1000,\n",
    "                epochs=50,\n",
<<<<<<< Updated upstream
=======
    "                steps_per_epoch=1000,\n",
>>>>>>> Stashed changes
    "                callbacks=callbacks,\n",
    "                validation_data=test_gen,\n",
    "                shuffle=True,\n",
    "                workers=1,\n",
    "                max_queue_size=10,\n",
    "                use_multiprocessing=False\n",
    "              )\n",
    "    return combined_net\n",
    "\n",
<<<<<<< Updated upstream
    "for i in range(7):\n",
=======
    "for i in range(10, 20):\n",
>>>>>>> Stashed changes
    "    train_model(data_folder + '_combined_' + str(i) + '.h5')\n",
    "    publish_model(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_2_sim3_combined_1.h5 0.21737819504043962 0.21737819504043962\n",
      "4_2_sim3_model1\n"
     ]
    }
   ],
   "source": [
    "publish_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
